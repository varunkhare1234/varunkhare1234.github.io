<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deep_learning on Varun</title>
    <link>https://vkkhare.github.io/tags/deep_learning/</link>
    <description>Recent content in deep_learning on Varun</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Nov 2019 01:50:11 +0100</lastBuildDate>
    
	    <atom:link href="https://vkkhare.github.io/tags/deep_learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Paper Summary: biologically plausible networks</title>
      <link>https://vkkhare.github.io/post/biological_networks/</link>
      <pubDate>Fri, 15 Nov 2019 01:50:11 +0100</pubDate>
      
      <guid>https://vkkhare.github.io/post/biological_networks/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1811.03567.pdf&#34;&gt;Biologically-Plausible Learning Algorithms Can Scale to Large Datasets&lt;/a&gt;
by Will Xiao[1], Honglin Chen[2], Qianli Liao[2] and Tomaso Poggio[2]&lt;/p&gt;
&lt;p&gt;[1] Department of Molecular and Cellular Biology, Harvard University&lt;/p&gt;
&lt;p&gt;[2] Center for Brains, Minds, and Machines, MIT&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Consider a layer in a feedforward neural network. Let &lt;strong&gt;x&lt;/strong&gt;i denote the input to the i th neuron in the layer and &lt;strong&gt;y&lt;/strong&gt;j the output of the j th neuron. Let &lt;strong&gt;W&lt;/strong&gt; denote the feedforward weight matrix and &lt;strong&gt;W&lt;/strong&gt;ij the connection between input &lt;strong&gt;x&lt;/strong&gt;i and output &lt;strong&gt;y&lt;/strong&gt;. Let f denote the activation function. Then, Equation 1 describes the computation in the feedforward step. The feedback step propagates the error signals using equation 2.






&lt;figure&gt;

&lt;img src=&#34;bp-1.png&#34; &gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If &lt;strong&gt;B=W&lt;/strong&gt;¬†we have standard backpropagation algorithm&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sign Symmetry Backpropagation Algorithm has¬†&lt;strong&gt;B = sign(W)&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feedback Alignment Backpropagation Algorithm has¬†&lt;strong&gt;B&lt;/strong&gt; as a random fixed matrix&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;h3 id=&#34;sign-symmetry&#34;&gt;SIGN SYMMETRY&lt;/h3&gt;
&lt;p&gt;Imagenet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sign symmetry only slightly underperformed Backprop on Imagenet.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No effect of having backprop in the last layer unlike FA&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Better than FA likely because sign information allows for easier feedforward and feedback weights alignment&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;bp_angles.png&#34; &gt;

&lt;img src=&#34;bp_angles.png&#34; &gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;feedback-alignment&#34;&gt;FEEDBACK ALIGNMENT&lt;/h3&gt;
&lt;p&gt;According to &lt;a href=&#34;https://www.nature.com/articles/ncomms13276&#34;&gt;lilicrap et. al&lt;/a&gt; even though the feedback weights are random the error signals still lie within the 90 degrees of true error signals calculated from backprop. Thus the model is still capable of moving along the real direction.&lt;/p&gt;
&lt;p&gt;Imagenet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Better than reported by &lt;a href=&#34;https://arxiv.org/abs/1807.04587&#34;&gt;bartunov et al&lt;/a&gt; if backprop used to train the final classification. The authors claim the exact error calculation (loss evaluation) is likely not softmax so it can come by a different mechanism.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/ncomms13276&#34;&gt;Lillicrap et al.&lt;/a&gt; (2016) show that with feedback alignment, the alignment angles between feedforward and feedback weights gradually decrease because the feedforward weights learn to align with the feedback weights&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;interesting-lines-of-work-and-validation-experiments&#34;&gt;Interesting lines of work and validation experiments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The existence of the feedforward and feedback pathways specifically aligned in an antiparallel way to justify sign symmetry.&lt;/li&gt;
&lt;li&gt;Incorporation of Dale&amp;rsquo;s Law so as to ensure neurons don&amp;rsquo;t change their sign during the entire learning process.
BP, FA, all of the TP variants, and indeed most known activation propagation algorithms (for an exception see Sacramento et al), still require distinct forward and backward (or ‚Äúpositive‚Äù and ‚Äúnegative‚Äù) phases. The existence of these phases is still a matter of research.&lt;/li&gt;
&lt;li&gt;I would like to understand how the feedback pathway will behave on continuous error signals or long term errors. Like with our previous discussions, based on region and cell type they specifically undergo LTP or LTD.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>KotlinSyft</title>
      <link>https://vkkhare.github.io/project/kotlinsyft/</link>
      <pubDate>Thu, 11 Jul 2019 10:02:51 +0530</pubDate>
      
      <guid>https://vkkhare.github.io/project/kotlinsyft/</guid>
      <description>&lt;p&gt;KotlinSyft makes it easy for you to &lt;strong&gt;train and execute PySyft models on Android devices&lt;/strong&gt;. This allows you to utilize training data located directly on the device itself, bypassing the need to send a user&amp;rsquo;s data to a central server. This is known as &lt;a href=&#34;https://ai.googleblog.com/2017/04/federated-learning-collaborative.html&#34;&gt;federated learning&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‚öô &lt;strong&gt;Training and inference&lt;/strong&gt; of any PySyft model written in PyTorch or TensorFlow&lt;/li&gt;
&lt;li&gt;üë§ Allows all data to stay on the user&amp;rsquo;s device&lt;/li&gt;
&lt;li&gt;‚ö° Support for full multi-threading / background service execution&lt;/li&gt;
&lt;li&gt;üîë Support for &lt;strong&gt;JWT authentication&lt;/strong&gt; to protect models from Sybil attacks&lt;/li&gt;
&lt;li&gt;üëç A set of &lt;strong&gt;inbuilt best practices&lt;/strong&gt; to prevent apps from over using device resources.
&lt;ul&gt;
&lt;li&gt;üîå &lt;strong&gt;Charge detection&lt;/strong&gt; to allow background training only when device is connected to charger&lt;/li&gt;
&lt;li&gt;üí§ &lt;strong&gt;Sleep and wake detection&lt;/strong&gt; so that the app does not occupy resource when user starts using the device&lt;/li&gt;
&lt;li&gt;üí∏ &lt;strong&gt;Wifi and metered network detection&lt;/strong&gt; to ensure the model updates do not use all the available data quota&lt;/li&gt;
&lt;li&gt;üîï All of these smart defaults are easily are &lt;strong&gt;overridable&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;üéì Support for both reactive and callback patterns so you have your freedom of choice (&lt;em&gt;in progress&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;üîí Support for &lt;strong&gt;secure multi-party computation&lt;/strong&gt; and &lt;strong&gt;secure aggregation&lt;/strong&gt; protocols using &lt;strong&gt;peer-to-peer WebRTC&lt;/strong&gt; connections (&lt;em&gt;in progress&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are a variety of additional privacy-preserving protections that may be applied, including &lt;a href=&#34;https://towardsdatascience.com/understanding-differential-privacy-85ce191e198a&#34;&gt;differential privacy&lt;/a&gt;, &lt;a href=&#34;https://www.inpher.io/technology/what-is-secure-multiparty-computation&#34;&gt;muliti-party computation&lt;/a&gt;, and &lt;a href=&#34;https://research.google/pubs/pub45808/&#34;&gt;secure aggregation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openmined.org&#34;&gt;OpenMined&lt;/a&gt; set out to build the &lt;strong&gt;world&amp;rsquo;s first open-source ecosystem for federated learning on web and mobile&lt;/strong&gt;. KotlinSyft is a part of this ecosystem, responsible for bringing secure federated learning to Android devices. You may also train models on iOS devices using &lt;a href=&#34;https://github.com/OpenMined/SwiftSyft&#34;&gt;SwiftSyft&lt;/a&gt; or in web browsers using &lt;a href=&#34;https://github.com/OpenMined/syft.js&#34;&gt;syft.js&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want to know how scalable federated systems are built, &lt;a href=&#34;https://arxiv.org/pdf/1902.01046.pdf&#34;&gt;Towards Federated Learning at Scale&lt;/a&gt; is a fantastic introduction!&lt;/p&gt;
&lt;p&gt;Join us in the movement at &lt;a href=&#34;http://slack.openmined.org/&#34;&gt;Slack&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adversarial Corruption</title>
      <link>https://vkkhare.github.io/project/adversarial-corruption/</link>
      <pubDate>Wed, 11 Apr 2018 09:57:10 +0530</pubDate>
      
      <guid>https://vkkhare.github.io/project/adversarial-corruption/</guid>
      <description>&lt;p&gt;Neural Networks have been observed to be robust to even adversarial corruptions. However, only a handful of theoretical results exist which guarantee robustness of NNs. We have made an attempt to address this, using results and techniques from robust statistics.
To measure the robustness of an algorithm, we want to derive its breakdown point which is the largest number of adversarially corrupted points an algorithm can handle and still guarantee recovery. The presence of breakdown point results for simpler learners like linear regression was a primary motivation to pursue this project using robust statistics.&lt;/p&gt;
&lt;p&gt;To simplify the problem, we consider the case of regression only single hidden layer neural networks with ReLU activation on each node and an output node with no activation with squared loss function. We analysed two different training procedures and how it can change the training trajectory to affect the final convergence. One apprach utilised the property of &lt;strong&gt;ReLU&lt;/strong&gt; of dividing the input space into 2 halves (active and unactive). Another approach split the problem as a difference of convex functions and we used alternating optimization to train it. This training procedure was well behaved in terms of convergence and theoretically sound.&lt;/p&gt;
&lt;p&gt;For complete details about these approaches please look in the attached pdf.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Word Problem Solver</title>
      <link>https://vkkhare.github.io/project/word-problem-solver/</link>
      <pubDate>Thu, 23 Nov 2017 09:57:28 +0530</pubDate>
      
      <guid>https://vkkhare.github.io/project/word-problem-solver/</guid>
      <description>&lt;h3 id=&#34;problem-statement&#34;&gt;&lt;strong&gt;Problem Statement&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Given a preliminary word problem based on speed, time and distance
relationship in natural language, generate a step-by-step solution for it&lt;/p&gt;
&lt;h3 id=&#34;proposed-solution&#34;&gt;&lt;strong&gt;Proposed Solution&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Our approach to solve mathematical word problems is based on the ability of represent the problem via relationships between various object described in the text. We start out by creating a graph which represents the hypothetical world described in the problem with a global function space defining the rules/association between different types of objects.&lt;/p&gt;
&lt;p&gt;We keep on adding nodes in the graph as when a new object (Noun Phrase) appears in the text and depict the association between two objects by an edge between them. If multiple functions are there multiple types of edges need to be created. If a Noun Phrase is an anaphora, all the objects which would have been linked to this noun phrase would instead be linked with the representative mention and node corresponding to the current Noun Phrase won‚Äôt be added to the graph.&lt;/p&gt;
&lt;p&gt;A set of nodes are eligible as arguments for a function iff they correspond to the object types used in the functional relationship and are connected by edges corresponding to the function. Each measurable quantity has a value attribute associated to it which
stores the value of that quantity. Once the graph is generated, we need to calculate the value of the query node. To do this, we traverse the graph starting DFS at query node (Top-Down approach) and check if we are able to calculate its value along any one of the computation path. We work recursively to evaluate all the nodes of the computation path from leaf and then finally evaluate the value of the root node. The following figures explain the graph construction.
&lt;img src=&#34;https://vkkhare.github.io/img/word_prob.png&#34; alt=&#34;automated concept graph generation&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The implimentation details are available in project report.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;testing&#34;&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The problems that it could understand were restricted and testing needed a controlled environment. The biggest challenge that we faced was handling prior world knowledge in the system. Currently, we only took those problem which didn‚Äôt need this world-knowledge for evaluation. This assumption seems a bit heavy so, we came up with an approach to incorporate it and have left it under future work for testing and validating its effectiveness.&lt;/p&gt;
&lt;p&gt;We also assumed that the problems didn‚Äôt need the knowledge of monotonic nature of the quantities and the association of words to modifications in the values of quantities like &lt;em&gt;Late&lt;/em&gt; w.r.t &lt;em&gt;time&lt;/em&gt; refers to addition of time to certain time object similarly longer w.r.t distance implies higher magnitude.&lt;/p&gt;
&lt;p&gt;Owing to a deterministic algorithm for query solving, if the system was able to understand the language it gives the correct answer. So, we took a set of 11 different type of problems that needed only Distance = Speed*Time as relationship. Out of these we were able to solve 7 problems some of which are mentioned below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How much time Raman will take to cover a distance of 400 km if he runs at a speed of 20 kmph ?&lt;/li&gt;
&lt;li&gt;The distance between two stations is 240 km. A train takes 4 hours to cover that distance. Calculate the speed of the train.&lt;/li&gt;
&lt;li&gt;A person runs a distance of 60 km in 5 hours. What is his speed ?&lt;/li&gt;
&lt;li&gt;Nancy travelled a distance of 455 km by car in 10 hours. Find the speed of the car.&lt;/li&gt;
&lt;li&gt;Ramesh travels at a speed of 30 kmph for a time of 2 hours to travel a certain distance. How much time will he take to cover that distance if his new speed is 20 kmph?&lt;/li&gt;
&lt;li&gt;If it takes 3 hours to drive a distance of 192 km on a motorway, what would be your speed?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;future-tasks&#34;&gt;&lt;strong&gt;Future Tasks&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We propose the following methods to overcome the challenges mentioned earlier and would be following our future work in this direction to improve the system:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Automating the graph generation for any type of problem&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Graph Neural Nets are highly effective in handling word to graph manipulations. They should work out better in handling linking between different objects.&lt;/li&gt;
&lt;li&gt;The monotonic and sequential nature of the quantities can be derived using Semantic Role Labeller. This would be helpful in adding word-to-quantity manipulations in general.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Synonymous descriptions like associating length to distance, age to time can be worked by training a ML classifier to associate these labels to noun-phrases. Semantic similarity or paraphrase matching systems might work out better in these.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are some relationships which are not given by function space but rather by ownership like a distance travelled by a car is owned by the agent(car). Such relationships can help in handling ambiguity in associating quantities together.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
