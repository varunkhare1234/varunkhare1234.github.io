<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>object_detection on Varun</title>
    <link>https://vkkhare.github.io/tags/object_detection/</link>
    <description>Recent content in object_detection on Varun</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2019 10:02:51 +0530</lastBuildDate>
    
	    <atom:link href="https://vkkhare.github.io/tags/object_detection/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Zero Shot Object Detection</title>
      <link>https://vkkhare.github.io/project/zero-shot-object-detection/</link>
      <pubDate>Thu, 11 Jul 2019 10:02:51 +0530</pubDate>
      
      <guid>https://vkkhare.github.io/project/zero-shot-object-detection/</guid>
      <description>&lt;p&gt;Zero shot detection greatly exacerbates the the problem of zero shot recognition. Not only training the classifiers pose a problem, we have to make the region proposal network learn to detect objects from unseen categories. These during training typically lie in the background.&lt;/p&gt;

&lt;p&gt;Our novelty lies in exploiting the visual consistency of the attributes via learning to detect attributes first and then combining these detections by a combinator module into final object detections. We employ spatial transformer networks to propagate the gradients across the combinator and RPNs. This was necessary due to unavailability of external bounding box annotations for attributes. It made it impossible to train RPN and combinator independently from classifier unlike faster-RCNN style architectures.&lt;/p&gt;

&lt;p&gt;This is work in progress and we aim to publish our results soon.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
